{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7473e24",
   "metadata": {},
   "source": [
    "# Forecasting future e-commerce sales\n",
    "\n",
    "In the dynamic landscape of e-commerce, accurately predicting units sold is crucial for ensuring optimal inventory management and maximizing revenue. Moreover, understanding the impact of marketing expenditure, especially during campaign periods, is essential for crafting effective strategies to drive sales and customer engagement. \n",
    "\n",
    "By comparing forecasting models like VARIMA from DARTS library, Prophet by Meta, and ForecasterAutoreg from SKForecast, e-commerce businesses can unlock powerful insights into consumer behavior and market trends. These models offer sophisticated tools to analyze historical sales data alongside marketing initiatives, enabling businesses to forecast units sold with greater precision and anticipate the effects of marketing campaigns or web traffic trends on future sales. Through this comparative analysis, e-commerce stakeholders can enhance their predictive capabilities, optimize resource allocation, and make data-driven decisions that propel their businesses to success in the competitive online marketplace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e257919f",
   "metadata": {},
   "source": [
    "## Pre-processing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a289ae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements needed\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2089bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Error metrics to measure our models performance\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a863d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "data = pd.read_csv('time_series_dataframe.csv')\n",
    "\n",
    "print(\"Are there any missing values?\")\n",
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f4fd37",
   "metadata": {},
   "source": [
    "### Fill the missing values\n",
    "To handle a specific column and interpolate missing values when seven consecutive days are missing, you can use the interpolate()\n",
    "\n",
    "method='linear': Assumes a linear relationship between consecutive points, regardless of the time intervals between them. It works well when the time intervals between data points are relatively constant.\n",
    "\n",
    "method='time': Takes into account the time intervals between data points when interpolating. It considers the time component, making it more suitable for time series data where the intervals between data points are irregular or unevenly spaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf1adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value imputation using linear interpolation\n",
    "data = data.interpolate(method='linear')\n",
    "\n",
    "print(\"Are there any missing values?\")\n",
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daef744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to the right types\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data['users'] = pd.to_numeric(data['users'], errors='coerce')\n",
    "data['sessions'] = pd.to_numeric(data['sessions'], errors='coerce')\n",
    "data['marketing_cost'] = pd.to_numeric(data['marketing_cost'], errors='coerce')\n",
    "data['clicks'] = pd.to_numeric(data['clicks'], errors='coerce')\n",
    "data['impressions'] = pd.to_numeric(data['impressions'], errors='coerce')\n",
    "data['click_through_rate'] = pd.to_numeric(data['click_through_rate'], errors='coerce')\n",
    "data['avg_time_on_page'] = pd.to_numeric(data['avg_time_on_page'], errors='coerce')\n",
    "data['bouce_rate'] = pd.to_numeric(data['bouce_rate'], errors='coerce')\n",
    "data['units_sold'] = pd.to_numeric(data['units_sold'], errors='coerce')\n",
    "data['is_campaign_period'] = pd.to_numeric(data['is_campaign_period'], errors='coerce')\n",
    "data['day_of_week'] = pd.to_numeric(data['day_of_week'], errors='coerce')\n",
    "data['month_number'] = pd.to_numeric(data['month_number'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4578cdcd",
   "metadata": {},
   "source": [
    "### Define the parameters for the models\n",
    "We need to define what are the amount of periods (days in this case) we want to predict and the last date of our training set. In other words, we define the date where the predictions will start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1524d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods_to_predict = 30\n",
    "end_training_date = '2023-02-19'\n",
    "# end_training_date = '2023-03-19'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744c6a23",
   "metadata": {},
   "source": [
    "### Split our data into train and test\n",
    "Based on the defined parameters, the data gets split for training and forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data before the determined end training date\n",
    "data_train = data[data['date'] < end_training_date]\n",
    "\n",
    "# Create date with end_training_date + periods_to_predict\n",
    "last_forecasting_date = data_train.date.max() + pd.Timedelta(days=periods_to_predict + 1)\n",
    "\n",
    "# Create dataframe with all data (past and future). This is important because we need to feed the \n",
    "#   models with future regressors\n",
    "all_data = data[data['date'] < last_forecasting_date]\n",
    "\n",
    "# Create dataframe with all available data until end training date\n",
    "data_test = data[(data['date'] < last_forecasting_date) & (data['date'] >= end_training_date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521b789c",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## DARTS: Forecasting with VARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2986864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from darts.models import VARIMA\n",
    "from darts import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting relevant columns for analysis\n",
    "data_train_selected = data_train[['date', 'users', 'units_sold', 'sessions', \n",
    "                                  'clicks', 'impressions', 'click_through_rate', 'avg_time_on_page']]\n",
    "\n",
    "# Converting dataframe to a time series\n",
    "series = TimeSeries.from_dataframe(data_train_selected, 'date', ['units_sold', 'users', 'sessions', \n",
    "                                                                 'avg_time_on_page', 'click_through_rate'])\n",
    "\n",
    "# Since we want to be more accurate on our forecasts and explain what impacts our predictions, \n",
    "#   we include regressors or exogenous variables in the models\n",
    "future_cov = TimeSeries.from_dataframe(all_data, 'date', ['marketing_cost', 'is_campaign_period'])\n",
    "pred_cov = TimeSeries.from_dataframe(data_test, 'date', ['marketing_cost', 'is_campaign_period'])\n",
    "\n",
    "# Initializing the VARIMA model with trend\n",
    "model = VARIMA(trend = 'ct')\n",
    "\n",
    "# Fitting the VARIMA model\n",
    "model.fit(series, future_covariates = future_cov)\n",
    "\n",
    "# Generating predictions for the next 15 time points\n",
    "pred = model.predict(periods_to_predict, future_covariates = pred_cov)\n",
    "pred.values()\n",
    "\n",
    "# Extracting forecasted values for 'units_sold'\n",
    "forecast_values = pred.univariate_component('units_sold').values()\n",
    "\n",
    "# Extracting actual values for 'units_sold'\n",
    "actual_data = data_test.tail(periods_to_predict)['units_sold'].values\n",
    "\n",
    "# Calculating metrics to evaluate model performance\n",
    "mae_darts = mean_absolute_error(actual_data, forecast_values)\n",
    "rmse_darts = np.sqrt(mean_squared_error(actual_data, forecast_values))\n",
    "\n",
    "# Print results\n",
    "print(\"mean_absolute_error:\", mae_darts)\n",
    "print(\"mean_squared_error:\", rmse_darts)\n",
    "\n",
    "# Extracting dates for x-axis\n",
    "dates = pd.to_datetime(data_test.tail(periods_to_predict)['date'])\n",
    "\n",
    "# Plotting actual values\n",
    "plt.plot(dates, actual_data, label='Actual')\n",
    "\n",
    "# Plotting forecasted values\n",
    "plt.plot(dates, forecast_values, label='Forecast', linestyle='dashed')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Units Sold')\n",
    "plt.title('Actual vs Forecasted Values')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping labels\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61321204",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Machine Learning approach: SKForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f82bbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419741a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_skforecast(df):\n",
    "    \"\"\"\n",
    "    Process the DataFrame by converting the 'date' column to datetime format,\n",
    "    setting it as the index, resampling to daily frequency, and sorting by date.\n",
    "    \n",
    "    Args:\n",
    "    df (DataFrame): Input DataFrame with a 'date' column\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Processed DataFrame with datetime index\n",
    "    \"\"\"\n",
    "    # Convert 'date' column to datetime format\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "    \n",
    "    # Set 'date' column as index\n",
    "    df = df.set_index('date')\n",
    "    \n",
    "    # Resample to daily frequency\n",
    "    df = df.asfreq('D')\n",
    "    \n",
    "    # Sort DataFrame by date\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply function over datasets for skforecast\n",
    "data_train_skforecast = process_data_skforecast(data_train)\n",
    "data_test_skforecast = process_data_skforecast(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c97612",
   "metadata": {},
   "source": [
    "### Autoregressive model\n",
    "\n",
    "A autoregressive model (ForecasterAutoreg) is trained using a linear regressor with Ridge regularization, and a time window of 2 weeks (14 lags). The latter means that, for each prediction, the traffic the website had in the previous 14 days is used as predictors.\n",
    "\n",
    "Ridge models require predictors to be standardized. A StandardScaler is added to the forecaster using the argument transformer_y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 14\n",
    "             )\n",
    "\n",
    "forecaster.fit(\n",
    "    y    = data_train_skforecast['units_sold'],\n",
    "    exog = data_train_skforecast[['marketing_cost', 'is_campaign_period']]\n",
    ")\n",
    "\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d178968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "# ==============================================================================\n",
    "steps = periods_to_predict\n",
    "predictions = forecaster.predict(\n",
    "                  steps = steps,\n",
    "                  exog = data_test_skforecast[['marketing_cost', 'is_campaign_period']]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe16bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating metrics to evaluate model performance\n",
    "mae_skforecast = mean_absolute_error(actual_data, predictions)\n",
    "rmse_skforecast = mean_squared_error(actual_data, predictions, squared=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"mean_absolute_error:\", mae_skforecast)\n",
    "print(\"mean_squared_error:\", rmse_skforecast)\n",
    "\n",
    "# Plotting actual values\n",
    "plt.plot(data_test_skforecast.index, data_test['units_sold'], label='Actual')\n",
    "\n",
    "# Plotting forecasted values\n",
    "plt.plot(data_test_skforecast.index, predictions, label='Forecast', linestyle='dashed')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Units Sold')\n",
    "plt.title('Actual vs Forecasted Values')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b6f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show what are the most important features that explain the predictions\n",
    "#  Note: lag_1 refers to the values from the previous day; lag_2 to the values from 2 days ago; and so on\n",
    "forecaster.get_feature_importances().sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5620d8",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Forecasting with Prophet from Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "# Selecting relevant columns for analysis\n",
    "data_train_selected = data_train[['date', 'users', 'units_sold', 'sessions', 'clicks', 'impressions', 'click_through_rate', 'avg_time_on_page', 'marketing_cost', 'is_campaign_period']]\n",
    "\n",
    "# Converting dataframe to a time series\n",
    "data_train_selected.columns = ['ds'] + data_train_selected.columns[1:].tolist()\n",
    "data_train_selected = data_train_selected.rename(columns={'units_sold': 'y'})\n",
    "series = data_train_selected\n",
    "\n",
    "# Initializing the Prophet model\n",
    "model = Prophet()\n",
    "\n",
    "# Adding regressors to the model\n",
    "for regressor in ['marketing_cost', 'is_campaign_period']:\n",
    "    model.add_regressor(regressor)\n",
    "\n",
    "# Fitting the Prophet model\n",
    "model.fit(series)\n",
    "\n",
    "# Creating future dataframe for prediction\n",
    "future_df = model.make_future_dataframe(periods=periods_to_predict)\n",
    "\n",
    "# Adding regressor values to the future dataframe\n",
    "for regressor in ['marketing_cost', 'is_campaign_period']:\n",
    "    future_df[regressor] = all_data[regressor].values\n",
    "\n",
    "# Generating predictions\n",
    "forecast = model.predict(future_df)\n",
    "\n",
    "# Extracting forecasted values for 'units_sold'\n",
    "forecast_values_prophet = forecast[['ds', 'yhat']].tail(periods_to_predict)['yhat'].values\n",
    "\n",
    "# Extracting actual values\n",
    "actual_data = data_test.tail(periods_to_predict)['units_sold'].values\n",
    "\n",
    "# Calculating metrics to evaluate model performance\n",
    "mae_prophet = mean_absolute_error(actual_data, forecast_values_prophet)\n",
    "rmse_prophet = np.sqrt(mean_squared_error(actual_data, forecast_values_prophet))\n",
    "\n",
    "print(\"mean_absolute_error:\", mae_prophet)\n",
    "print(\"mean_squared_error:\", rmse_prophet)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(data_test.tail(periods_to_predict)['date'], actual_data, label='Actual')\n",
    "plt.plot(data_test.tail(periods_to_predict)['date'], forecast_values_prophet, label='Forecast', linestyle='dashed')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Units Sold')\n",
    "plt.title('Actual vs Forecasted Values')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc8df55",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Compare the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edce3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset with the required error values\n",
    "model_error_comparison = {\n",
    "    'MAE': {\n",
    "        'prophet': mae_prophet,\n",
    "        'skforecast': mae_skforecast,\n",
    "        'darts': mae_darts\n",
    "    },\n",
    "    'RMSE': {\n",
    "        'prophet': rmse_prophet,\n",
    "        'skforecast': rmse_skforecast,\n",
    "        'darts': rmse_darts\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create a DataFrame object and display it\n",
    "model_error_comparison = pd.DataFrame(model_error_comparison).sort_values(by='MAE', ascending=True)\n",
    "model_error_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting dates for x-axis\n",
    "dates = pd.to_datetime(data_test.tail(periods_to_predict)['date'])\n",
    "\n",
    "# Plotting actual values\n",
    "plt.plot(dates, actual_data, label='Actual')\n",
    "\n",
    "# Plotting forecasted values for each model\n",
    "plt.plot(dates, forecast_values, label='DARTS', linestyle='dashed')\n",
    "plt.plot(dates, predictions, label='SKForecast', linestyle='dashed')\n",
    "plt.plot(dates, forecast_values_prophet, label='Prophet', linestyle='dashed')\n",
    "\n",
    "# Show chart with all forecasts\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Units Sold')\n",
    "plt.title('Actual vs Forecasted Values')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping labels\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
